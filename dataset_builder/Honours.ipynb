{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "import pickle\n",
    "import sqlite3\n",
    "import IPython\n",
    "import fnmatch\n",
    "import copyreg\n",
    "import imagehash\n",
    "import subprocess\n",
    "from math import exp\n",
    "from PIL import Image\n",
    "import multiprocessing\n",
    "from pprint import pprint\n",
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "\n",
    "def thread_it(thread_function, my_list, tq=True, WORKERS=None):\n",
    "    # Set worker number to CPU count\n",
    "    if not WORKERS:\n",
    "        WORKERS = multiprocessing.cpu_count()\n",
    "    \n",
    "    if tq:\n",
    "        tq = tqdm(total=len(my_list))\n",
    "    \n",
    "    # Separate into chunks and execute threaded\n",
    "    thread_list = chunks(my_list, WORKERS)\n",
    "    for chunk in thread_list:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=WORKERS) as executor:\n",
    "            for item in chunk:\n",
    "                executor.submit(thread_function, item)\n",
    "                if tq:\n",
    "                    tq.update(1)\n",
    "    tq.close()\n",
    "\n",
    "\n",
    "\n",
    "def thread_it_return(thread_function, my_list, tq=True, WORKERS=None):\n",
    "    # Set worker number to CPU count\n",
    "    if not WORKERS:\n",
    "        WORKERS = multiprocessing.cpu_count()\n",
    "    \n",
    "    if tq:\n",
    "        tq = tqdm(total=len(my_list))\n",
    "        \n",
    "    results = []\n",
    "    # Separate into chunks and execute threaded\n",
    "    thread_list = chunks(my_list, WORKERS)\n",
    "    for chunk in thread_list:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=WORKERS) as executor:\n",
    "            for item in chunk:\n",
    "                future = executor.submit(thread_function, item)\n",
    "                \n",
    "                return_value = future.result()\n",
    "                if return_value != None:\n",
    "                    results.append(return_value)\n",
    "                    \n",
    "                if tq:\n",
    "                    tq.update(1)\n",
    "    \n",
    "    tq.close()\n",
    "    \n",
    "    return results\n",
    "    \n",
    "\n",
    "def show_img_by_path(a, resize=True, size=(320, 240)):\n",
    "    # I could and probably need to implement image scaling beforehand, for network access\n",
    "    img = Image.open(a)\n",
    "    if resize:\n",
    "        img = img.resize(size=size)\n",
    "    IPython.display.display(img)\n",
    "\n",
    "\n",
    "def create_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define various variables\n",
    "#### This includes all paths for image folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should already exist from the \"Download\"\n",
    "compare_dir = \"compare_set/\"\n",
    "data_dir = \"images/\"\n",
    "\n",
    "\n",
    "consider_dir = \"consider/\"\n",
    "problems = \"problems/\"\n",
    "blurry = \"blurry/\"\n",
    "\n",
    "dirs = [consider_dir, blurry, problems]\n",
    "for path in dirs:\n",
    "    create_folder(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "#### Get blur variance average for the comparison set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def blur_avg_thread(image):\n",
    "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    val = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    return val \n",
    "\n",
    "def get_blur_average(path, multiplier=1):\n",
    "    files = glob.glob(path+\"*.jpg\", recursive=True)\n",
    "    thr = thread_it_return(blur_avg_thread, files)\n",
    "    avg = sum(thr) / len(files)\n",
    "    return avg * multiplier\n",
    "\n",
    "blur_avg = get_blur_average(compare_dir, multiplier=0.75)\n",
    "print(\"The blur average is: \", blur_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Get the images in the data set that are more blurry than a given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def too_blurry_thread(item):\n",
    "    image = item[\"image\"]\n",
    "    threshold = item[\"threshold\"]\n",
    "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    val = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    if val < threshold:\n",
    "        return image\n",
    "                \n",
    "def get_too_blurry(path, threshold):\n",
    "    files = glob.glob(path+\"*.jpg\")\n",
    "    items = []\n",
    "    for image in files:\n",
    "        items.append({\"image\": image, \"threshold\": threshold})\n",
    "    too_blurry = thread_it_return(too_blurry_thread, items)\n",
    "    \n",
    "    print(\"{} out of {} images are blurry\".format(len(too_blurry), len(files)))\n",
    "    return too_blurry\n",
    "\n",
    "#too_blurry = get_too_blurry(data_dir, blur_avg)\n",
    "#https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "# Temporary override to check how a constant of 200 does.\n",
    "too_blurry = get_too_blurry(data_dir, 200)\n",
    "# Well, it does pretty damn good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the files referred to by the paths in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to(file_list, dest):\n",
    "    tq = tqdm(total=len(file_list))\n",
    "    exception_flag = False\n",
    "    for item in file_list:\n",
    "        try:\n",
    "            shutil.move(item, dest)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            exception_flag = True\n",
    "        tq.update(1)\n",
    "    tq.close()\n",
    "    return exception_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if move_to(too_blurry, blurry):\n",
    "    del(too_blurry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "#### Hashing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hash_thread(image):\n",
    "    fname = image.split(\".\")[-2]+\".hsh\"\n",
    "    if not os.path.isfile(fname):\n",
    "        img_hash = imagehash.dhash(Image.open(image))\n",
    "        pickle.dump(img_hash, open(fname, \"wb\"))    \n",
    "\n",
    "def compute_img_hashes(path):\n",
    "    files = glob.glob(path+\"*.jpg\")\n",
    "    thread_it(hash_thread, files)\n",
    "\n",
    "compute_img_hashes(compare_dir)\n",
    "compute_img_hashes(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute hash distances for each image to each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hash_distance_thread(item):\n",
    "    hash1 = pickle.load(open(item[\"hashname\"], \"rb\"))\n",
    "    dis = item[\"hashname\"].split(\".\")[-2]+\".dis\"\n",
    "    check = item[\"hashname\"].split(\".\")[-2]+\".jpg\"\n",
    "    \n",
    "    if os.path.isfile(dis):\n",
    "        compute = pickle.load(open(dis, \"rb\"))\n",
    "    else:\n",
    "        compute = {}\n",
    "    \n",
    "    for hashpath in item[\"files\"]:\n",
    "        try:\n",
    "            image = hashpath.split(\".\")[-2]+\".jpg\"\n",
    "            if image not in compute.keys() and image != check:\n",
    "                hash2 = pickle.load(open(hashpath, \"rb\"))\n",
    "                compute[image] = hash1 - hash2\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    pickle.dump(compute, open(dis, \"wb\"))\n",
    "\n",
    "def compute_hash_distance(path):\n",
    "    files = glob.glob(path+\"*.hsh\")\n",
    "    \n",
    "    items = []\n",
    "    for image in files:\n",
    "        items.append({\"hashname\": image, \"files\": files})\n",
    "\n",
    "    thread_it(hash_distance_thread, items)\n",
    "\n",
    "compute_hash_distance(compare_dir)    \n",
    "compute_hash_distance(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_duplicate_images(path, threshold=10):\n",
    "    files = glob.glob(path+\"*.dis\")\n",
    "    dup, close = [], []\n",
    "    \n",
    "    for path in files:\n",
    "        distances = pickle.load(open(path, \"rb\"))\n",
    "        img = path.split(\".\")[-2]+\".jpg\"\n",
    "        \n",
    "        for key, val in distances.items():\n",
    "            if val == 0:\n",
    "                if key not in dup and img not in dup:\n",
    "                    dup.append(key)\n",
    "            elif val < threshold:\n",
    "                if key not in close and img not in close:\n",
    "                    close.append(key)\n",
    "                \n",
    "    return dup, close\n",
    "\n",
    "compare_dup, compare_close = get_duplicate_images(compare_dir, threshold=5)\n",
    "data_dup, data_close = get_duplicate_images(data_dir, threshold=5)\n",
    "\n",
    "print(\"Compare duplicates:\")\n",
    "pprint(compare_dup)\n",
    "print(\"Compare close:\")\n",
    "pprint(compare_close)\n",
    "\n",
    "print(\"Data duplicates:\")\n",
    "pprint(data_dup)\n",
    "print(\"Data close:\")\n",
    "pprint(data_close)\n",
    "\n",
    "show = False\n",
    "if show:\n",
    "    print(\"DUPLICATES IN COMPARE:\")\n",
    "    for item in compare_dup:\n",
    "        show_img_by_path(item)\n",
    "    print(\"DUPLICATES IN DATA:\")\n",
    "    for item in data_dup:\n",
    "        show_img_by_path(item)\n",
    "    print(\"CLOSE IN COMPARE:\")\n",
    "    for item in compare_close:\n",
    "        show_img_by_path(item)\n",
    "    print(\"CLOSE IN DATA:\")\n",
    "    for item in data_close:\n",
    "        show_img_by_path(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if move_to(compare_dup, problems):\n",
    "    del(compare_dup)\n",
    "if move_to(data_dup, problems):\n",
    "    del(data_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction (Comparison set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd = r\"colmap feature_extractor --database_path ./colmap_folder/colmap.sqlite3 --image_path compare_set/ --SiftExtraction.max_num_features 2048\"\n",
    "process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "print(output.splitlines()[-1])\n",
    "print(\"Finished extracting features from Comparison set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matching (Comparison set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cmd = r\"colmap exhaustive_matcher --database_path ./colmap_folder/colmap.sqlite3\"\n",
    "process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "print(output.splitlines()[-1])\n",
    "print(\"Finished matching features from Comparison set\")"
   ]
  },
  {
   "source": [
    "## Database Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file, timeout=30000)\n",
    "        dest = sqlite3.connect(':memory:')\n",
    "        conn.backup(dest)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return dest\n",
    "\n",
    "def delete_from(conn, table, column_name, where_value):\n",
    "    sql = r\"DELETE FROM {} WHERE {}='{}'\".format(table, column_name, where_value)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "\n",
    "def select_what_from_where(conn, what, table, where_name, where_value):\n",
    "    cur = conn.cursor()\n",
    "    row = cur.execute(r\"SELECT {} FROM {} WHERE {}='{}'\".format(what, table, column_name, where_value)).fetchone()\n",
    "    conn.commit()\n",
    "    return row\n",
    "\n",
    "def select_what_from(conn, what, table):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(r\"SELECT {} FROM {}\".format(what, table))\n",
    "    conn.commit()\n",
    "    rows = cur.fetchall()\n",
    "    conn.commit()\n",
    "    return rows\n",
    "\n",
    "def decrement_cameras(conn):\n",
    "    sql = r\"UPDATE sqlite_sequence SET seq = seq - 1 WHERE name='cameras'\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "\n",
    "def decrement_images(conn):\n",
    "    sql = r\"UPDATE sqlite_sequence SET seq = seq - 1 WHERE name='images'\"\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://colmap.github.io/database.html\n",
    "def pair_id_to_image_ids(pair_id):\n",
    "    image_id2 = pair_id % 2147483647\n",
    "    image_id1 = (pair_id - image_id2) / 2147483647\n",
    "    return image_id1, image_id2\n",
    "\n",
    "def load_matches(conn):\n",
    "    matches = {}\n",
    "    id_to_img = {}\n",
    "    for row in select_what_from(conn, \"image_id, name\", \"images\"):\n",
    "        img_id = row[0]\n",
    "        name = row[1]\n",
    "        id_to_img[img_id] = name\n",
    "\n",
    "    for img in id_to_img.values():\n",
    "        matches[img] = {}\n",
    "\n",
    "    for row in select_what_from(conn, \"pair_id, rows\", \"matches\"):\n",
    "        pair_id = row[0]\n",
    "        img1id, img2id = pair_id_to_image_ids(pair_id)\n",
    "        num_matches = row[1]\n",
    "        img1name, img2name = id_to_img[img1id], id_to_img[img2id]\n",
    "        matches[img1name][img2name] = num_matches\n",
    "        matches[img2name][img1name] = num_matches\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "    return matches\n",
    "\n",
    "conn = create_connection(\"./colmap_folder/colmap.sqlite3\")\n",
    "compare_matches = load_matches(conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{&#39;image_010d209e7868c373442bd62dc19551a8.jpg&#39;: 4018,\n &#39;image_02edbd010eac8a8076cb4e9fbfe40b0d.jpg&#39;: 4737,\n &#39;image_03f2ce4031203591db026ea0b7f7a164.jpg&#39;: 229,\n &#39;image_048203bccf979cc3bbc3a9cb525486d2.jpg&#39;: 151,\n &#39;image_0647bf1c96468264221555ad19df45af.jpg&#39;: 4183,\n &#39;image_075a0568bb3549140aeb743239f9fc50.jpg&#39;: 4114,\n &#39;image_07ef018ed0ecd5d5b8970c5db570d2a8.jpg&#39;: 427,\n &#39;image_0a267444ea542710f6d1261aec4cdede.jpg&#39;: 44,\n &#39;image_0b74808c6f93d3eaa36d973a8aadb336.jpg&#39;: 6269,\n &#39;image_0b89967e0767c7fa910b9f570612206d.jpg&#39;: 3802,\n &#39;image_0b91b2443d738c7c17d5c0ef0214440d.jpg&#39;: 3438,\n &#39;image_0b9815e25c221742e410ac401231c1f7.jpg&#39;: 2355,\n &#39;image_0de2fbea71c4ef65b5b2b3209fa287e3.jpg&#39;: 435,\n &#39;image_0ef489424c1de58a34d126b3780deb5a.jpg&#39;: 4986,\n &#39;image_1041982b1a050e369bdcdef421ec7294.jpg&#39;: 298,\n &#39;image_1706e115f358603dc116d5e4137e6092.jpg&#39;: 1507,\n &#39;image_17128ba882609a83e644c7162b952fc8.jpg&#39;: 5197,\n &#39;image_1816dc6880683ced4c8c908844e5778b.jpg&#39;: 766,\n &#39;image_199a469cdf240bc1082ba0036d1d2ad4.jpg&#39;: 3061,\n &#39;image_1b937e3ac238ea17640fec8d008c1252.jpg&#39;: 0,\n &#39;image_1c3ddf1539c6eed0e531ccebf4a6b53a.jpg&#39;: 5883,\n &#39;image_1e8056e309fd0e0131fabc9743bbdaa6.jpg&#39;: 3880,\n &#39;image_1f83e4d1d78ea2dc18c008e497895c69.jpg&#39;: 2735,\n &#39;image_24b636a91be856dc26fff3c09eb9515c.jpg&#39;: 169,\n &#39;image_271843d660bfbfe38d8507718f85dd9d.jpg&#39;: 5161,\n &#39;image_2bbfe04efa58e73d9aee7b73cc7eb445.jpg&#39;: 452,\n &#39;image_2c9e6555f2396c69fa8fddb84513f467.jpg&#39;: 121,\n &#39;image_32857c59727123b133044f91839e3030.jpg&#39;: 179,\n &#39;image_36170c0d39d8fb9735989a6bb0d3b314.jpg&#39;: 1228,\n &#39;image_392feefb59352ed3b90d8be55e04f652.jpg&#39;: 5443,\n &#39;image_39324655b5385e889d9534cf13a43c7a.jpg&#39;: 145,\n &#39;image_395e96e9affb6ce40b6d68b3fd3038a0.jpg&#39;: 167,\n &#39;image_3e38f729091607a9dc1cfd86f3fd012f.jpg&#39;: 80,\n &#39;image_3f3b64d42fce0d076e571cec84da65c0.jpg&#39;: 5890,\n &#39;image_3f656bb20e156a03f5ab848718a08c84.jpg&#39;: 717,\n &#39;image_40b0da029b8e518b4fd4f762c5c34236.jpg&#39;: 24,\n &#39;image_41b5a014db1d45619100f4fd056cccf2.jpg&#39;: 2827,\n &#39;image_43a4e5825d7bae3538cf296014550298.jpg&#39;: 6208,\n &#39;image_4c167188c6d9e1958f9f786a6a97557e.jpg&#39;: 2284,\n &#39;image_4c4a3997f715246b83b51032175a8e2c.jpg&#39;: 1097,\n &#39;image_4d319f3fcf359a10e879de21c93571ce.jpg&#39;: 748,\n &#39;image_51bc8a963e3e64d96f2e2b9bed10b63e.jpg&#39;: 1033,\n &#39;image_52b4274397dcae47af6db95b2cc29e4a.jpg&#39;: 436,\n &#39;image_560c9961476e97adc806a2d7fffb1a94.jpg&#39;: 4673,\n &#39;image_5836fac060f5629abcc9642e3e3b8af4.jpg&#39;: 362,\n &#39;image_593412fa41615c6fa9756b229318a9d1.jpg&#39;: 324,\n &#39;image_5be70eb6495aa9e9552ce6bf2bf627f4.jpg&#39;: 1994,\n &#39;image_5c3d68a57604204ef927d0c9a723bdfb.jpg&#39;: 3259,\n &#39;image_5c50054c6668a3f187f5d1c3eca2a240.jpg&#39;: 4997,\n &#39;image_5e9c068db85b6d1539429bb1b19e846d.jpg&#39;: 5365,\n &#39;image_5f8b11aaa3c4ea9f388baf00a8989905.jpg&#39;: 0,\n &#39;image_5fcd5eec2e3cf5249f42a0720b81ff3f.jpg&#39;: 3190,\n &#39;image_628c32df361cc2aea4e8eaa22b1047b1.jpg&#39;: 187,\n &#39;image_62cb5da1fa5e666bf40366fb292373ad.jpg&#39;: 505,\n &#39;image_66041cf9f115a9c9ad34d6014a1631d2.jpg&#39;: 1238,\n &#39;image_697fef72278cced7bc321ce65203068a.jpg&#39;: 256,\n &#39;image_6bcfa7fe18be11082769a337f82ef560.jpg&#39;: 17,\n &#39;image_6e97aadab4d45dcb31482b7cfdf04f4b.jpg&#39;: 914,\n &#39;image_6ebd535bab353c4418484b9bbd1d0ff7.jpg&#39;: 360,\n &#39;image_6fb83397635551df36d4192de4129e9a.jpg&#39;: 188,\n &#39;image_70d9274e93b9e59f644cd82ed7933596.jpg&#39;: 235,\n &#39;image_71f50fac17a6f756a5b134bc792fb260.jpg&#39;: 4028,\n &#39;image_7615b9d75719e1f2a7405a55be01f1e5.jpg&#39;: 4436,\n &#39;image_76e9607936e00ef6217662b6ba2e4514.jpg&#39;: 65,\n &#39;image_77638b5b251c13f04e17eda42757d065.jpg&#39;: 1535,\n &#39;image_7b1fa82aae3e6e31abf1fc1467e0c309.jpg&#39;: 3317,\n &#39;image_7d017d5cd3de3da20ee615e4e15083aa.jpg&#39;: 343,\n &#39;image_7e5cbe47135694796236c54824e03fb5.jpg&#39;: 1602,\n &#39;image_8292fc978a49360ca92c1b1646a76964.jpg&#39;: 71,\n &#39;image_858a1a01739ae986c635c445b6c4ff0b.jpg&#39;: 15,\n &#39;image_8805e1ca620789e421f206a04ff99b59.jpg&#39;: 352,\n &#39;image_8abc1f330f4c96f33c34d26412c7547a.jpg&#39;: 182,\n &#39;image_8c2f99e57acd7dcaeddc9e82a2f50e0e.jpg&#39;: 56,\n &#39;image_8c42430359a6778365d3363002a410a1.jpg&#39;: 1838,\n &#39;image_8d8c85331b527bae6d3cb6c992237a4a.jpg&#39;: 544,\n &#39;image_8e52e4db01dfb78ef1cc112257c801a2.jpg&#39;: 4017,\n &#39;image_9066493b3124023140a0b396d52bfec5.jpg&#39;: 2595,\n &#39;image_91274d7f072ae58715c4cea3b7c7bab6.jpg&#39;: 181,\n &#39;image_91aeeb8999b98199bb552e46f3e1d6d8.jpg&#39;: 0,\n &#39;image_91e7681abff658f74eee39812b63ea57.jpg&#39;: 2195,\n &#39;image_9440111c4ffd171ab2db0cde930a8d8d.jpg&#39;: 5421,\n &#39;image_94e61d0a19004108a722323cf2b5d22c.jpg&#39;: 3477,\n &#39;image_96d24321edb9e6d720c78e00bf95b9f0.jpg&#39;: 0,\n &#39;image_99234bf3ee16ff6301968c43f70f5df9.jpg&#39;: 3023,\n &#39;image_993135e271b21053cd23906107e2b949.jpg&#39;: 2508,\n &#39;image_99dfdbbb7b788ad5c046df729a949fed.jpg&#39;: 1124,\n &#39;image_9e5f1e122ad3608157655dd13add38b5.jpg&#39;: 0,\n &#39;image_a46346aca673693544ed5ea0e7b8cc6d.jpg&#39;: 219,\n &#39;image_a48e3ac1c0f8cad37dbe6f057d36aac2.jpg&#39;: 4894,\n &#39;image_a5c2647694f1a3726176d43557d6b363.jpg&#39;: 2844,\n &#39;image_a7239bb158bef2e993efb6a810de23ba.jpg&#39;: 5430,\n &#39;image_a765648f1e5dade59c2a21f7b7c127b2.jpg&#39;: 150,\n &#39;image_a848f31df3428e53cbd5ef5a417127dd.jpg&#39;: 241,\n &#39;image_a885bdc9b4c005926d701d5f40187864.jpg&#39;: 0,\n &#39;image_a937ccd7a1fb0d04f517695dd8136d0c.jpg&#39;: 2953,\n &#39;image_a9a195abfe6baf85f698180a4f4c9134.jpg&#39;: 2098,\n &#39;image_ab7fddd12a801c2c2ea1f6f6be41b9a7.jpg&#39;: 675,\n &#39;image_ac98d23b3267209053c0c4ca15c59d53.jpg&#39;: 5464,\n &#39;image_aef1439c96dbfc6d8b8efa649901e3f4.jpg&#39;: 2630,\n &#39;image_af24f43210fcdc6da2e2a48e50ddffea.jpg&#39;: 65,\n &#39;image_b2d9eadb2a12cbffa592b65a9223edb5.jpg&#39;: 142,\n &#39;image_b4a4e8048ab494879e7ce14d82890f9a.jpg&#39;: 264,\n &#39;image_b4bc1152d7aa17beee04367c03d6368b.jpg&#39;: 341,\n &#39;image_b57cfe958c0fa84b9234b46b8e41f3bb.jpg&#39;: 336,\n &#39;image_c4c37a518148b10f45f545fa9eff94e3.jpg&#39;: 2349,\n &#39;image_c66a61da73a340f7418ecc1642040573.jpg&#39;: 67,\n &#39;image_c93f12a4cbecdf46ee04c142fc9cd192.jpg&#39;: 1436,\n &#39;image_d110c662245a8357755fc22d7d217bec.jpg&#39;: 205,\n &#39;image_d18813cc5e10f26e6748a39a1d0a098e.jpg&#39;: 2987,\n &#39;image_d1cd3323c5c72d651cf38ed89f8d917c.jpg&#39;: 1968,\n &#39;image_d4eb11480a328220608b948cda1a7294.jpg&#39;: 2249,\n &#39;image_d79be8f60afccf802c3ef1397efdbe31.jpg&#39;: 436,\n &#39;image_d9793f4d9d4dfeec4f47167076f7ac8b.jpg&#39;: 2560,\n &#39;image_dc5ca9193596f4f0f181754a421aca67.jpg&#39;: 620,\n &#39;image_dd703606494fdf450721f3102d91de97.jpg&#39;: 42,\n &#39;image_e112ba6cb05a1f55b9716ec49699f907.jpg&#39;: 154,\n &#39;image_e4908eb5fb71dd5b6abcf84b2974ea2c.jpg&#39;: 2672,\n &#39;image_e5f3f9d9f7f3598c7683889e37e997e2.jpg&#39;: 15,\n &#39;image_e6a19e95901a2eff74be323c6287d737.jpg&#39;: 4913,\n &#39;image_e73ace6163232515ca3e6fd7ec88ceb3.jpg&#39;: 2608,\n &#39;image_e7402bee3b8c76a001db162e3fe0489c.jpg&#39;: 3983,\n &#39;image_e812058ef92a5d64396bea8c9625678c.jpg&#39;: 609,\n &#39;image_e81d2f24ea14edecdaa850b6ffddbc37.jpg&#39;: 365,\n &#39;image_eae93855d3b4813f26029f5057e0d35b.jpg&#39;: 6206,\n &#39;image_edb3cc5e2c984952afb9cfd04342c37f.jpg&#39;: 2100,\n &#39;image_ee53a4a378ba0aca3a9b9d8ba10eb1b3.jpg&#39;: 121,\n &#39;image_eed1efafa2d3551b5a9d0cb48c11c518.jpg&#39;: 2830,\n &#39;image_ef749f27a25093105da1ee2714bcc726.jpg&#39;: 859,\n &#39;image_f060d4d05c4ecde34a6c5a69a7ce5184.jpg&#39;: 134,\n &#39;image_f2e7780e207ff77981e9917de1b39ba6.jpg&#39;: 227,\n &#39;image_f3de69d3167e8788557c0b435a4cc9ba.jpg&#39;: 569,\n &#39;image_f466cd1f696e4045b6c2321634d816d5.jpg&#39;: 25,\n &#39;image_f6030008ffb688c019e39abce37b45d2.jpg&#39;: 33,\n &#39;image_f6165e7f35d3ebad8f6bfa0b1fb024b4.jpg&#39;: 37,\n &#39;image_f81986898baf9c4e5cbe4de025f61eb9.jpg&#39;: 849,\n &#39;image_f824ffdb30081302d7844548ecbe99a7.jpg&#39;: 977,\n &#39;image_f98b346af5892c34e6f89aff6a293199.jpg&#39;: 3611,\n &#39;image_f9ad0f43471d039983a95676eae616a7.jpg&#39;: 4929,\n &#39;image_fa6303b375bc32318a66cc8329b27081.jpg&#39;: 5749,\n &#39;image_fd3dfa6f8fc71fb947f3cdcbccbbd45d.jpg&#39;: 44,\n &#39;image_fdb8efa7ad2f3aaf3451c8a64e956f7a.jpg&#39;: 322,\n &#39;image_fdbfc27162bcafbfa3df901a9c2b7624.jpg&#39;: 81,\n &#39;image_fe7d6fd36754808c508beb19ef3cf89d.jpg&#39;: 4884}\n"
    }
   ],
   "source": [
    "def total_matches(matches):\n",
    "    totals = {}\n",
    "    for key in matches.keys():\n",
    "        totals[key] = []\n",
    "    for key, value in matches.items():\n",
    "        length = len(value)\n",
    "        for _, num_matches in value.items():\n",
    "            totals[key].append(num_matches)\n",
    "    for key in totals.keys():\n",
    "        totals[key] = sum(totals[key])\n",
    "\n",
    "    return totals\n",
    "\n",
    "compare_total_matches = total_matches(compare_matches)\n",
    "# If one image doesn't match at all, either eliminate it (and rerun) or find more images for the set.\n",
    "pprint(compare_total_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate threshold from comparison set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thr_from_compare(totals, multipler=1):\n",
    "    thr_per_image = {}\n",
    "    \n",
    "    tq = tqdm(total=len(totals))\n",
    "    for img1, item in totals.items():\n",
    "        for img2, val in item.items():\n",
    "            thr = val * multipler\n",
    "            \n",
    "            # Add thr to dict\n",
    "            if img2 not in thr_per_image.keys():\n",
    "                thr_per_image[img2] = [thr]\n",
    "            else:\n",
    "                thr_per_image[img2].append(thr)\n",
    "        tq.update(1)\n",
    "\n",
    "    # Get the average feature match for a valid image for each image in the reference set to every other image\n",
    "    for key in thr_per_image.keys():\n",
    "        val = thr_per_image[key]\n",
    "        thr_per_image[key] = sum(val)/len(val)\n",
    "        \n",
    "    return thr_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(HTML(value=&#39;&#39;), FloatProgress(value=0.0, max=143.0), HTML(value=&#39;&#39;)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4eca1784c5ca48a9b32f9922520cc781"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{&#39;image_010d209e7868c373442bd62dc19551a8.jpg&#39;: 24.051408450704216,\n &#39;image_02edbd010eac8a8076cb4e9fbfe40b0d.jpg&#39;: 28.355281690140846,\n &#39;image_03f2ce4031203591db026ea0b7f7a164.jpg&#39;: 1.370774647887324,\n &#39;image_048203bccf979cc3bbc3a9cb525486d2.jpg&#39;: 0.9038732394366197,\n &#39;image_0647bf1c96468264221555ad19df45af.jpg&#39;: 25.039084507042254,\n &#39;image_075a0568bb3549140aeb743239f9fc50.jpg&#39;: 24.626056338028167,\n &#39;image_07ef018ed0ecd5d5b8970c5db570d2a8.jpg&#39;: 2.555985915492957,\n &#39;image_0a267444ea542710f6d1261aec4cdede.jpg&#39;: 0.2633802816901408,\n &#39;image_0b74808c6f93d3eaa36d973a8aadb336.jpg&#39;: 37.52570422535211,\n &#39;image_0b89967e0767c7fa910b9f570612206d.jpg&#39;: 22.758450704225353,\n &#39;image_0b91b2443d738c7c17d5c0ef0214440d.jpg&#39;: 20.579577464788734,\n &#39;image_0b9815e25c221742e410ac401231c1f7.jpg&#39;: 14.096830985915494,\n &#39;image_0de2fbea71c4ef65b5b2b3209fa287e3.jpg&#39;: 2.6038732394366195,\n &#39;image_0ef489424c1de58a34d126b3780deb5a.jpg&#39;: 29.84577464788733,\n &#39;image_1041982b1a050e369bdcdef421ec7294.jpg&#39;: 1.7838028169014084,\n &#39;image_1706e115f358603dc116d5e4137e6092.jpg&#39;: 9.020774647887324,\n &#39;image_17128ba882609a83e644c7162b952fc8.jpg&#39;: 31.108802816901406,\n &#39;image_1816dc6880683ced4c8c908844e5778b.jpg&#39;: 4.585211267605634,\n &#39;image_199a469cdf240bc1082ba0036d1d2ad4.jpg&#39;: 18.322887323943657,\n &#39;image_1b937e3ac238ea17640fec8d008c1252.jpg&#39;: 0.0,\n &#39;image_1c3ddf1539c6eed0e531ccebf4a6b53a.jpg&#39;: 35.215140845070415,\n &#39;image_1e8056e309fd0e0131fabc9743bbdaa6.jpg&#39;: 23.225352112676052,\n &#39;image_1f83e4d1d78ea2dc18c008e497895c69.jpg&#39;: 16.371478873239436,\n &#39;image_24b636a91be856dc26fff3c09eb9515c.jpg&#39;: 1.0116197183098592,\n &#39;image_271843d660bfbfe38d8507718f85dd9d.jpg&#39;: 30.893309859154932,\n &#39;image_2bbfe04efa58e73d9aee7b73cc7eb445.jpg&#39;: 2.705633802816901,\n &#39;image_2c9e6555f2396c69fa8fddb84513f467.jpg&#39;: 0.7242957746478873,\n &#39;image_32857c59727123b133044f91839e3030.jpg&#39;: 1.0714788732394365,\n &#39;image_36170c0d39d8fb9735989a6bb0d3b314.jpg&#39;: 7.350704225352114,\n &#39;image_392feefb59352ed3b90d8be55e04f652.jpg&#39;: 32.581338028169,\n &#39;image_39324655b5385e889d9534cf13a43c7a.jpg&#39;: 0.8679577464788732,\n &#39;image_395e96e9affb6ce40b6d68b3fd3038a0.jpg&#39;: 0.9996478873239436,\n &#39;image_3e38f729091607a9dc1cfd86f3fd012f.jpg&#39;: 0.4788732394366197,\n &#39;image_3f3b64d42fce0d076e571cec84da65c0.jpg&#39;: 35.257042253521114,\n &#39;image_3f656bb20e156a03f5ab848718a08c84.jpg&#39;: 4.291901408450704,\n &#39;image_40b0da029b8e518b4fd4f762c5c34236.jpg&#39;: 0.14366197183098592,\n &#39;image_41b5a014db1d45619100f4fd056cccf2.jpg&#39;: 16.92218309859155,\n &#39;image_43a4e5825d7bae3538cf296014550298.jpg&#39;: 37.16056338028167,\n &#39;image_4c167188c6d9e1958f9f786a6a97557e.jpg&#39;: 13.67183098591549,\n &#39;image_4c4a3997f715246b83b51032175a8e2c.jpg&#39;: 6.566549295774649,\n &#39;image_4d319f3fcf359a10e879de21c93571ce.jpg&#39;: 4.477464788732395,\n &#39;image_51bc8a963e3e64d96f2e2b9bed10b63e.jpg&#39;: 6.183450704225352,\n &#39;image_52b4274397dcae47af6db95b2cc29e4a.jpg&#39;: 2.6098591549295778,\n &#39;image_560c9961476e97adc806a2d7fffb1a94.jpg&#39;: 27.972183098591543,\n &#39;image_5836fac060f5629abcc9642e3e3b8af4.jpg&#39;: 2.166901408450704,\n &#39;image_593412fa41615c6fa9756b229318a9d1.jpg&#39;: 1.9394366197183097,\n &#39;image_5be70eb6495aa9e9552ce6bf2bf627f4.jpg&#39;: 11.935915492957744,\n &#39;image_5c3d68a57604204ef927d0c9a723bdfb.jpg&#39;: 19.5080985915493,\n &#39;image_5c50054c6668a3f187f5d1c3eca2a240.jpg&#39;: 29.91161971830985,\n &#39;image_5e9c068db85b6d1539429bb1b19e846d.jpg&#39;: 32.1144366197183,\n &#39;image_5f8b11aaa3c4ea9f388baf00a8989905.jpg&#39;: 0.0,\n &#39;image_5fcd5eec2e3cf5249f42a0720b81ff3f.jpg&#39;: 19.09507042253521,\n &#39;image_628c32df361cc2aea4e8eaa22b1047b1.jpg&#39;: 1.1193661971830986,\n &#39;image_62cb5da1fa5e666bf40366fb292373ad.jpg&#39;: 3.0228873239436624,\n &#39;image_66041cf9f115a9c9ad34d6014a1631d2.jpg&#39;: 7.410563380281691,\n &#39;image_697fef72278cced7bc321ce65203068a.jpg&#39;: 1.532394366197183,\n &#39;image_6bcfa7fe18be11082769a337f82ef560.jpg&#39;: 0.10176056338028168,\n &#39;image_6e97aadab4d45dcb31482b7cfdf04f4b.jpg&#39;: 5.47112676056338,\n &#39;image_6ebd535bab353c4418484b9bbd1d0ff7.jpg&#39;: 2.1549295774647885,\n &#39;image_6fb83397635551df36d4192de4129e9a.jpg&#39;: 1.1253521126760562,\n &#39;image_70d9274e93b9e59f644cd82ed7933596.jpg&#39;: 1.4066901408450705,\n &#39;image_71f50fac17a6f756a5b134bc792fb260.jpg&#39;: 24.111267605633802,\n &#39;image_7615b9d75719e1f2a7405a55be01f1e5.jpg&#39;: 26.55352112676057,\n &#39;image_76e9607936e00ef6217662b6ba2e4514.jpg&#39;: 0.3890845070422535,\n &#39;image_77638b5b251c13f04e17eda42757d065.jpg&#39;: 9.18838028169014,\n &#39;image_7b1fa82aae3e6e31abf1fc1467e0c309.jpg&#39;: 19.855281690140846,\n &#39;image_7d017d5cd3de3da20ee615e4e15083aa.jpg&#39;: 2.053169014084507,\n &#39;image_7e5cbe47135694796236c54824e03fb5.jpg&#39;: 9.589436619718308,\n &#39;image_8292fc978a49360ca92c1b1646a76964.jpg&#39;: 0.425,\n &#39;image_858a1a01739ae986c635c445b6c4ff0b.jpg&#39;: 0.0897887323943662,\n &#39;image_8805e1ca620789e421f206a04ff99b59.jpg&#39;: 2.1070422535211266,\n &#39;image_8abc1f330f4c96f33c34d26412c7547a.jpg&#39;: 1.0894366197183099,\n &#39;image_8c2f99e57acd7dcaeddc9e82a2f50e0e.jpg&#39;: 0.3352112676056338,\n &#39;image_8c42430359a6778365d3363002a410a1.jpg&#39;: 11.00211267605634,\n &#39;image_8d8c85331b527bae6d3cb6c992237a4a.jpg&#39;: 3.2563380281690137,\n &#39;image_8e52e4db01dfb78ef1cc112257c801a2.jpg&#39;: 24.045422535211266,\n &#39;image_9066493b3124023140a0b396d52bfec5.jpg&#39;: 15.533450704225348,\n &#39;image_91274d7f072ae58715c4cea3b7c7bab6.jpg&#39;: 1.083450704225352,\n &#39;image_91aeeb8999b98199bb552e46f3e1d6d8.jpg&#39;: 0.0,\n &#39;image_91e7681abff658f74eee39812b63ea57.jpg&#39;: 13.139084507042254,\n &#39;image_9440111c4ffd171ab2db0cde930a8d8d.jpg&#39;: 32.449647887323955,\n &#39;image_94e61d0a19004108a722323cf2b5d22c.jpg&#39;: 20.81302816901408,\n &#39;image_96d24321edb9e6d720c78e00bf95b9f0.jpg&#39;: 0.0,\n &#39;image_99234bf3ee16ff6301968c43f70f5df9.jpg&#39;: 18.095422535211256,\n &#39;image_993135e271b21053cd23906107e2b949.jpg&#39;: 15.012676056338032,\n &#39;image_99dfdbbb7b788ad5c046df729a949fed.jpg&#39;: 6.728169014084506,\n &#39;image_9e5f1e122ad3608157655dd13add38b5.jpg&#39;: 0.0,\n &#39;image_a46346aca673693544ed5ea0e7b8cc6d.jpg&#39;: 1.3109154929577465,\n &#39;image_a48e3ac1c0f8cad37dbe6f057d36aac2.jpg&#39;: 29.295070422535208,\n &#39;image_a5c2647694f1a3726176d43557d6b363.jpg&#39;: 17.023943661971828,\n &#39;image_a7239bb158bef2e993efb6a810de23ba.jpg&#39;: 32.50352112676057,\n &#39;image_a765648f1e5dade59c2a21f7b7c127b2.jpg&#39;: 0.8978873239436619,\n &#39;image_a848f31df3428e53cbd5ef5a417127dd.jpg&#39;: 1.4426056338028168,\n &#39;image_a885bdc9b4c005926d701d5f40187864.jpg&#39;: 0.0,\n &#39;image_a937ccd7a1fb0d04f517695dd8136d0c.jpg&#39;: 17.67640845070422,\n &#39;image_a9a195abfe6baf85f698180a4f4c9134.jpg&#39;: 12.558450704225352,\n &#39;image_ab7fddd12a801c2c2ea1f6f6be41b9a7.jpg&#39;: 4.040492957746479,\n &#39;image_ac98d23b3267209053c0c4ca15c59d53.jpg&#39;: 32.707042253521145,\n &#39;image_aef1439c96dbfc6d8b8efa649901e3f4.jpg&#39;: 15.74295774647887,\n &#39;image_af24f43210fcdc6da2e2a48e50ddffea.jpg&#39;: 0.3890845070422535,\n &#39;image_b2d9eadb2a12cbffa592b65a9223edb5.jpg&#39;: 0.8499999999999999,\n &#39;image_b4a4e8048ab494879e7ce14d82890f9a.jpg&#39;: 1.5802816901408447,\n &#39;image_b4bc1152d7aa17beee04367c03d6368b.jpg&#39;: 2.0411971830985913,\n &#39;image_b57cfe958c0fa84b9234b46b8e41f3bb.jpg&#39;: 2.011267605633803,\n &#39;image_c4c37a518148b10f45f545fa9eff94e3.jpg&#39;: 14.060915492957744,\n &#39;image_c66a61da73a340f7418ecc1642040573.jpg&#39;: 0.401056338028169,\n &#39;image_c93f12a4cbecdf46ee04c142fc9cd192.jpg&#39;: 8.595774647887325,\n &#39;image_d110c662245a8357755fc22d7d217bec.jpg&#39;: 1.2271126760563378,\n &#39;image_d18813cc5e10f26e6748a39a1d0a098e.jpg&#39;: 17.879929577464782,\n &#39;image_d1cd3323c5c72d651cf38ed89f8d917c.jpg&#39;: 11.780281690140841,\n &#39;image_d4eb11480a328220608b948cda1a7294.jpg&#39;: 13.462323943661971,\n &#39;image_d79be8f60afccf802c3ef1397efdbe31.jpg&#39;: 2.6098591549295778,\n &#39;image_d9793f4d9d4dfeec4f47167076f7ac8b.jpg&#39;: 15.32394366197183,\n &#39;image_dc5ca9193596f4f0f181754a421aca67.jpg&#39;: 3.711267605633803,\n &#39;image_dd703606494fdf450721f3102d91de97.jpg&#39;: 0.25140845070422535,\n &#39;image_e112ba6cb05a1f55b9716ec49699f907.jpg&#39;: 0.921830985915493,\n &#39;image_e4908eb5fb71dd5b6abcf84b2974ea2c.jpg&#39;: 15.994366197183103,\n &#39;image_e5f3f9d9f7f3598c7683889e37e997e2.jpg&#39;: 0.0897887323943662,\n &#39;image_e6a19e95901a2eff74be323c6287d737.jpg&#39;: 29.408802816901403,\n &#39;image_e73ace6163232515ca3e6fd7ec88ceb3.jpg&#39;: 15.611267605633808,\n &#39;image_e7402bee3b8c76a001db162e3fe0489c.jpg&#39;: 23.84190140845071,\n &#39;image_e812058ef92a5d64396bea8c9625678c.jpg&#39;: 3.645422535211268,\n &#39;image_e81d2f24ea14edecdaa850b6ffddbc37.jpg&#39;: 2.184859154929578,\n &#39;image_eae93855d3b4813f26029f5057e0d35b.jpg&#39;: 37.14859154929578,\n &#39;image_edb3cc5e2c984952afb9cfd04342c37f.jpg&#39;: 12.570422535211268,\n &#39;image_ee53a4a378ba0aca3a9b9d8ba10eb1b3.jpg&#39;: 0.7242957746478872,\n &#39;image_eed1efafa2d3551b5a9d0cb48c11c518.jpg&#39;: 16.94014084507042,\n &#39;image_ef749f27a25093105da1ee2714bcc726.jpg&#39;: 5.141901408450705,\n &#39;image_f060d4d05c4ecde34a6c5a69a7ce5184.jpg&#39;: 0.8021126760563381,\n &#39;image_f2e7780e207ff77981e9917de1b39ba6.jpg&#39;: 1.3588028169014084,\n &#39;image_f3de69d3167e8788557c0b435a4cc9ba.jpg&#39;: 3.4059859154929586,\n &#39;image_f466cd1f696e4045b6c2321634d816d5.jpg&#39;: 0.14964788732394366,\n &#39;image_f6030008ffb688c019e39abce37b45d2.jpg&#39;: 0.19753521126760562,\n &#39;image_f6165e7f35d3ebad8f6bfa0b1fb024b4.jpg&#39;: 0.2214788732394366,\n &#39;image_f81986898baf9c4e5cbe4de025f61eb9.jpg&#39;: 5.082042253521127,\n &#39;image_f824ffdb30081302d7844548ecbe99a7.jpg&#39;: 5.848239436619718,\n &#39;image_f98b346af5892c34e6f89aff6a293199.jpg&#39;: 21.615140845070428,\n &#39;image_f9ad0f43471d039983a95676eae616a7.jpg&#39;: 29.50457746478873,\n &#39;image_fa6303b375bc32318a66cc8329b27081.jpg&#39;: 34.41302816901408,\n &#39;image_fd3dfa6f8fc71fb947f3cdcbccbbd45d.jpg&#39;: 0.2633802816901408,\n &#39;image_fdb8efa7ad2f3aaf3451c8a64e956f7a.jpg&#39;: 1.9274647887323944,\n &#39;image_fdbfc27162bcafbfa3df901a9c2b7624.jpg&#39;: 0.48485915492957743,\n &#39;image_fe7d6fd36754808c508beb19ef3cf89d.jpg&#39;: 29.23521126760563}\n"
    }
   ],
   "source": [
    "thr_per_image = get_thr_from_compare(compare_matches, multipler=0.85)\n",
    "pprint(thr_per_image)"
   ]
  },
  {
   "source": [
    "## Calculating number of matches for each image (Data set) to entire comparison set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "LOADED compare_ids_to_img FROM PICKLE\nLength of &quot;compare_ids_to_img&quot;: 143\nLOADED comparison_only_pair_ids FROM PICKLE\nLength of &quot;comparison_only_pair_ids&quot;: 10153\n"
    },
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "&#39;image_00a6536bd2115e634b95c14f5aefbc66.jpg&#39;",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m&lt;ipython-input-53-8f13cc64c8ca&gt;\u001b[0m in \u001b[0;36m&lt;module&gt;\u001b[0;34m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_ids_to_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_ids_to_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--&gt; 140\u001b[0;31m             \u001b[0mmatches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_matches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mimg2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompare_ids_to_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mimg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare_ids_to_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: &#39;image_00a6536bd2115e634b95c14f5aefbc66.jpg&#39;"
     ]
    }
   ],
   "source": [
    "#https://colmap.github.io/database.html\n",
    "def image_ids_to_pair_id(image_id1, image_id2):\n",
    "    if image_id1 > image_id2:\n",
    "        return 2147483647 * image_id2 + image_id1\n",
    "    else:\n",
    "        return 2147483647 * image_id1 + image_id2\n",
    "\n",
    "def pair_id_to_image_ids(pair_id):\n",
    "    image_id2 = pair_id % 2147483647\n",
    "    image_id1 = (pair_id - image_id2) / 2147483647\n",
    "    return image_id1, image_id2\n",
    "\n",
    "def remove_img_from_db(conn, filename, compare_images, delete=False):\n",
    "    # Retrieve img_id and cam_id for image to delete\n",
    "    images_row = select_from_where(conn, \"images\", \"name\", filename)\n",
    "    img_id = images_row[0]\n",
    "    cam_id = images_row[2]\n",
    "\n",
    "    # Check if that's the only image referencing that camera.\n",
    "    images_rows = select_all(conn, \"images\")\n",
    "    only_cam_ref = True\n",
    "    for row in images_rows:\n",
    "        if row[2] == cam_id and row[0] != img_id:\n",
    "            # Cannot delete that camera\n",
    "            only_cam_ref = False\n",
    "\n",
    "    if only_cam_ref:\n",
    "        delete_from(conn, \"cameras\", \"camera_id\", cam_id)\n",
    "        decrement_cameras(conn)\n",
    "\n",
    "    # Delete any images, descriptors and keypoints for one data image record.\n",
    "    delete_from(conn, \"images\", \"name\", filename)\n",
    "    delete_from(conn, \"descriptors\", \"image_id\", img_id)\n",
    "    delete_from(conn, \"keypoints\", \"image_id\", img_id)\n",
    "\n",
    "\n",
    "    # Delete all matches and two_view_geometries for one data image to all comparison images\n",
    "    for compare_img in compare_images:\n",
    "        compare_filename = compare_img.split(\"/\")[-1]\n",
    "        try:\n",
    "            return_val = select_from_where(conn, \"images\", \"name\", compare_filename)\n",
    "            compare_img_id = return_val[0]\n",
    "        except Exception:\n",
    "            # If the return values is none, assume no matches for this image.\n",
    "            #print(compare_filename, return_val)\n",
    "            pass\n",
    "\n",
    "        pair_id = image_ids_to_pair_id(img_id, compare_img_id)\n",
    "\n",
    "        delete_from(conn, \"matches\", \"pair_id\", pair_id)\n",
    "        delete_from(conn, \"two_view_geometries\", \"pair_id\", pair_id)\n",
    "\n",
    "    decrement_images(conn)\n",
    "\n",
    "data_matches = {}\n",
    "conn = create_connection(\"./colmap_folder/colmap.sqlite3\")\n",
    "data_images = glob.glob(data_dir+\"*.jpg\")\n",
    "data_pair_matching = \"./colmap_folder/pairs_to_match.txt\"\n",
    "\n",
    "# Retrieve all img_ids and filenames for comparison set\n",
    "\n",
    "if os.path.isfile(\"./compare_ids_to_img.p\"):\n",
    "    comparison_only_pair_ids = pickle.load(open(\"./compare_ids_to_img.p\", \"rb\"))\n",
    "    print(\"LOADED compare_ids_to_img FROM PICKLE\")\n",
    "else:\n",
    "    compare_ids_to_img = {}\n",
    "    return_val = select_what_from(conn, \"image_id, name\", \"images\")\n",
    "    for row in return_val:\n",
    "        compare_img_id = row[0]\n",
    "        compare_img_filename = row[1]\n",
    "        compare_ids_to_img[compare_img_id] = compare_img_filename\n",
    "    pickle.dump(compare_ids_to_img, open(\"./compare_ids_to_img.p\", \"wb\"))\n",
    "print(\"Length of \\\"compare_ids_to_img\\\":\", len(compare_ids_to_img.keys()))\n",
    "\n",
    "# Get all comparison only pair_ids\n",
    "if os.path.isfile(\"./comparison_pair_ids.p\"):\n",
    "    comparison_only_pair_ids = pickle.load(open(\"./comparison_pair_ids.p\", \"rb\"))\n",
    "    print(\"LOADED comparison_only_pair_ids FROM PICKLE\")\n",
    "else:    \n",
    "    comparison_only_pair_ids = []\n",
    "    return_val = select_what_from(conn, \"pair_id\", \"matches\")\n",
    "    for row in return_val:\n",
    "        comparison_only_pair_ids.append(str(row[0]))\n",
    "    pickle.dump(comparison_only_pair_ids, open(\"./comparison_pair_ids.p\", \"wb\"))\n",
    "print(\"Length of \\\"comparison_only_pair_ids\\\":\",len(comparison_only_pair_ids))\n",
    "\n",
    "# Write all image pairings for each data image to each comparison image but not to other data images.\n",
    "for data_img in data_images:\n",
    "    data_filename = data_img.split(\"/\")[-1]\n",
    "\n",
    "    for compare_img in compare_ids_to_img.values():\n",
    "        #to_write = data_filename + \" \" + compare_img + \"\\n\"\n",
    "        to_write = data_filename + \" \" + compare_img + \"\\n\"\n",
    "        f = open(data_pair_matching, \"a\").write(to_write)\n",
    "\n",
    "cmd = r\"colmap feature_extractor --database_path ./colmap_folder/colmap.sqlite3 --image_path ./images --SiftExtraction.max_num_features 2048\"\n",
    "process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "p_status = process.wait()\n",
    "\n",
    "# Retrieve all img_ids and filenames for data set\n",
    "data_ids_to_img = {}\n",
    "return_val = select_what_from(conn, \"image_id, name\", \"images\")\n",
    "for row in return_val:\n",
    "    data_img_id = row[0]\n",
    "    data_img_filename = row[1]\n",
    "    # If not a comparison image\n",
    "    if data_img_id not in compare_ids_to_img.keys():\n",
    "        data_ids_to_img[data_img_id] = data_img_filename\n",
    "\n",
    "# Match all image pairs for data set.\n",
    "cmd = r\"colmap matches_importer --database_path ./colmap_folder/colmap.sqlite3 --match_list_path ./colmap_folder/pairs_to_match.txt\"\n",
    "process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "p_status = process.wait()\n",
    "#print(output)\n",
    "\n",
    "# WILL NEED FOR REPEAT\n",
    "os.remove(data_pair_matching)\n",
    "\n",
    "# Get all match numbers\n",
    "matches = {}\n",
    "return_val = select_what_from(conn, \"pair_id, rows\", \"matches\")\n",
    "#print(comparison_only_pair_ids)\n",
    "\n",
    "for row in return_val:\n",
    "    pair_id = str(row[0])\n",
    "    num_matches = row[1]\n",
    "    \n",
    "    if pair_id not in comparison_only_pair_ids:\n",
    "        img1, img2 = pair_id_to_image_ids(int(pair_id))\n",
    "        img1, img2 = int(img1), int(img2)\n",
    "        if img1 in compare_ids_to_img.keys():\n",
    "            img1 = compare_ids_to_img[img1]\n",
    "            img2 = data_ids_to_img[img2]\n",
    "            if img2 not in matches.keys():\n",
    "                matches[img2] = {}\n",
    "            matches[img2][img1] = num_matches\n",
    "        elif img2 in compare_ids_to_img.keys():\n",
    "            img2 = compare_ids_to_img[img2]\n",
    "            img1 = data_ids_to_img[img1]\n",
    "            if img1 not in matches.keys():\n",
    "                matches[img1] = {}\n",
    "            matches[img1][img2] = num_matches\n",
    "\n",
    "\n",
    "#pprint(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply threshold to data directory set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_threshold_items(totals, thr_per_image, show=False):\n",
    "    values = {}\n",
    "    #x, y = [], []\n",
    "    tq = tqdm(total=len(totals))\n",
    "    for img1, item in totals.items():\n",
    "        rating = 0\n",
    "        \n",
    "        for img2, val in item.items():\n",
    "            # If the \"Data\" image is under the thr for the comparison image\n",
    "            if val > thr_per_image[img2]:\n",
    "                # Show which images from the comparison set, the data image is under thr for, and how much\n",
    "                rating += 1\n",
    "        \n",
    "        if rating != 0:\n",
    "            rating = rating / len(item) \n",
    "        #rating = sigmoid(rating)\n",
    "\n",
    "        values[img1] = rating\n",
    "        \n",
    "        tq.update(1)\n",
    "    \"\"\"    \n",
    "    if show:\n",
    "        %matplotlib notebook\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(200, 200))\n",
    "        plt.plot(y, x, \"o\", color=\"black\")\n",
    "        plt.plot([x for x in range(len(x))], [confidence for x in range(len(x))], '-ok', color=\"red\")\n",
    "        plt.xlabel(\"Number of features\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        plt.show()\n",
    "        print(\"Average is \", confidence)\n",
    "    \"\"\"\n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#print(matches)\n",
    "ratings = get_threshold_items(matches, thr_per_image, show=False)\n",
    "#pprint(ratings)\n",
    "under_confidence = []\n",
    "confidence = sum(ratings.values()) / len(ratings)\n",
    "print(\"CONFIDENCE: {}\".format(confidence))\n",
    "for key, val in ratings.items():\n",
    "    if val < confidence:\n",
    "        print(key, \"@\", val)\n",
    "        under_confidence.append(key)\n",
    "        #show_img_by_path(key, size=(75,75))\n",
    "\n",
    "print(\"{} out of {} images are under confident\".format(len(under_confidence), len(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def move_threshold_items(under, consider_folder, do_print=False):\n",
    "    for val in under:\n",
    "        val = data_dir+val\n",
    "        if os.path.isfile(val):\n",
    "            filename = val.split(\"/\")[-1]\n",
    "            path = os.path.join(consider_folder, filename)\n",
    "            try:\n",
    "                shutil.move(val, consider_folder)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            print(val, \"doesn't exist\")\n",
    "\n",
    "move_threshold_items(under_confidence, consider_dir)"
   ]
  },
  {
   "source": [
    "# An idea; I could possibly smush all the feature data for the comparison images into one object... That would give me a nice percentage as an overall match."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}