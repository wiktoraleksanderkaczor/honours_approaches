{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "import cv2\n",
    "import time\n",
    "import glob\n",
    "import shutil\n",
    "import pickle\n",
    "import IPython\n",
    "import fnmatch\n",
    "import copyreg\n",
    "import imagehash\n",
    "from math import exp\n",
    "from PIL import Image\n",
    "import multiprocessing\n",
    "from pprint import pprint\n",
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "\n",
    "def thread_it(thread_function, my_list, tq=True, WORKERS=None):\n",
    "    # Set worker number to CPU count\n",
    "    if not WORKERS:\n",
    "        WORKERS = multiprocessing.cpu_count()\n",
    "    \n",
    "    if tq:\n",
    "        tq = tqdm(total=len(my_list))\n",
    "    \n",
    "    # Separate into chunks and execute threaded\n",
    "    thread_list = chunks(my_list, WORKERS)\n",
    "    for chunk in thread_list:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=WORKERS) as executor:\n",
    "            for item in chunk:\n",
    "                executor.submit(thread_function, item)\n",
    "                if tq:\n",
    "                    tq.update(1)\n",
    "    tq.close()\n",
    "\n",
    "\n",
    "\n",
    "def thread_it_return(thread_function, my_list, tq=True, WORKERS=None):\n",
    "    # Set worker number to CPU count\n",
    "    if not WORKERS:\n",
    "        WORKERS = multiprocessing.cpu_count()\n",
    "    \n",
    "    if tq:\n",
    "        tq = tqdm(total=len(my_list))\n",
    "        \n",
    "    results = []\n",
    "    # Separate into chunks and execute threaded\n",
    "    thread_list = chunks(my_list, WORKERS)\n",
    "    for chunk in thread_list:\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=WORKERS) as executor:\n",
    "            for item in chunk:\n",
    "                future = executor.submit(thread_function, item)\n",
    "                \n",
    "                return_value = future.result()\n",
    "                if return_value != None:\n",
    "                    results.append(return_value)\n",
    "                    \n",
    "                if tq:\n",
    "                    tq.update(1)\n",
    "    \n",
    "    tq.close()\n",
    "    \n",
    "    return results\n",
    "    \n",
    "\n",
    "def show_img_by_path(a, resize=True, size=(320, 240)):\n",
    "    # I could and probably need to implement image scaling beforehand, for network access\n",
    "    img = Image.open(a)\n",
    "    if resize:\n",
    "        img = img.resize(size=size)\n",
    "    IPython.display.display(img)\n",
    "\n",
    "\n",
    "def create_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define various variables\n",
    "#### This includes all paths for image folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These should already exist from the \"Download\"\n",
    "compare_dir = \"compare_set/\"\n",
    "data_dir = \"images/\"\n",
    "\n",
    "\n",
    "consider_dir = \"consider/\"\n",
    "problems = \"problems/\"\n",
    "blurry = \"blurry/\"\n",
    "\n",
    "dirs = [consider_dir, blurry, problems]\n",
    "for path in dirs:\n",
    "    create_folder(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "#### Get blur variance average for the comparison set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def blur_avg_thread(image):\n",
    "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    val = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    return val \n",
    "\n",
    "def get_blur_average(path, multiplier=1):\n",
    "    files = glob.glob(path+\"*.jpg\", recursive=True)\n",
    "    thr = thread_it_return(blur_avg_thread, files)\n",
    "    avg = sum(thr) / len(files)\n",
    "    return avg * multiplier\n",
    "\n",
    "blur_avg = get_blur_average(compare_dir, multiplier=0.75)\n",
    "print(\"The blur average is: \", blur_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Get the images in the data set that are more blurry than a given threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def too_blurry_thread(item):\n",
    "    image = item[\"image\"]\n",
    "    threshold = item[\"threshold\"]\n",
    "    img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    val = cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "    if val < threshold:\n",
    "        return image\n",
    "                \n",
    "def get_too_blurry(path, threshold):\n",
    "    files = glob.glob(path+\"*.jpg\")\n",
    "    items = []\n",
    "    for image in files:\n",
    "        items.append({\"image\": image, \"threshold\": threshold})\n",
    "    too_blurry = thread_it_return(too_blurry_thread, items)\n",
    "    \n",
    "    print(\"{} out of {} images are blurry\".format(len(too_blurry), len(files)))\n",
    "    return too_blurry\n",
    "\n",
    "#too_blurry = get_too_blurry(data_dir, blur_avg)\n",
    "#https://www.pyimagesearch.com/2015/09/07/blur-detection-with-opencv/\n",
    "# Temporary override to check how a constant of 200 does.\n",
    "too_blurry = get_too_blurry(data_dir, 200)\n",
    "# Well, it does pretty damn good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the files referred to by the paths in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to(file_list, dest):\n",
    "    tq = tqdm(total=len(file_list))\n",
    "    exception_flag = False\n",
    "    for item in file_list:\n",
    "        try:\n",
    "            shutil.move(item, dest)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            exception_flag = True\n",
    "        tq.update(1)\n",
    "    tq.close()\n",
    "    return exception_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if move_to(too_blurry, blurry):\n",
    "    del(too_blurry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "#### Hashing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hash_thread(image):\n",
    "    fname = image.split(\".\")[-2]+\".hsh\"\n",
    "    if not os.path.isfile(fname):\n",
    "        img_hash = imagehash.dhash(Image.open(image))\n",
    "        pickle.dump(img_hash, open(fname, \"wb\"))    \n",
    "\n",
    "def compute_img_hashes(path):\n",
    "    files = glob.glob(path+\"*.jpg\")\n",
    "    thread_it(hash_thread, files)\n",
    "\n",
    "compute_img_hashes(compare_dir)\n",
    "compute_img_hashes(data_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute hash distances for each image to each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hash_distance_thread(item):\n",
    "    hash1 = pickle.load(open(item[\"hashname\"], \"rb\"))\n",
    "    dis = item[\"hashname\"].split(\".\")[-2]+\".dis\"\n",
    "    check = item[\"hashname\"].split(\".\")[-2]+\".jpg\"\n",
    "    \n",
    "    if os.path.isfile(dis):\n",
    "        compute = pickle.load(open(dis, \"rb\"))\n",
    "    else:\n",
    "        compute = {}\n",
    "    \n",
    "    for hashpath in item[\"files\"]:\n",
    "        try:\n",
    "            image = hashpath.split(\".\")[-2]+\".jpg\"\n",
    "            if image not in compute.keys() and image != check:\n",
    "                hash2 = pickle.load(open(hashpath, \"rb\"))\n",
    "                compute[image] = hash1 - hash2\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    pickle.dump(compute, open(dis, \"wb\"))\n",
    "\n",
    "def compute_hash_distance(path):\n",
    "    files = glob.glob(path+\"*.hsh\")\n",
    "    \n",
    "    items = []\n",
    "    for image in files:\n",
    "        items.append({\"hashname\": image, \"files\": files})\n",
    "\n",
    "    thread_it(hash_distance_thread, items)\n",
    "\n",
    "compute_hash_distance(compare_dir)    \n",
    "compute_hash_distance(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_duplicate_images(path, threshold=10):\n",
    "    files = glob.glob(path+\"*.dis\")\n",
    "    dup, close = [], []\n",
    "    \n",
    "    for path in files:\n",
    "        distances = pickle.load(open(path, \"rb\"))\n",
    "        img = path.split(\".\")[-2]+\".jpg\"\n",
    "        \n",
    "        for key, val in distances.items():\n",
    "            if val == 0:\n",
    "                if key not in dup and img not in dup:\n",
    "                    dup.append(key)\n",
    "            elif val < threshold:\n",
    "                if key not in close and img not in close:\n",
    "                    close.append(key)\n",
    "                \n",
    "    return dup, close\n",
    "\n",
    "compare_dup, compare_close = get_duplicate_images(compare_dir, threshold=5)\n",
    "data_dup, data_close = get_duplicate_images(data_dir, threshold=5)\n",
    "\n",
    "print(\"Compare duplicates:\")\n",
    "pprint(compare_dup)\n",
    "print(\"Compare close:\")\n",
    "pprint(compare_close)\n",
    "\n",
    "print(\"Data duplicates:\")\n",
    "pprint(data_dup)\n",
    "print(\"Data close:\")\n",
    "pprint(data_close)\n",
    "\n",
    "show = False\n",
    "if show:\n",
    "    print(\"DUPLICATES IN COMPARE:\")\n",
    "    for item in compare_dup:\n",
    "        show_img_by_path(item)\n",
    "    print(\"DUPLICATES IN DATA:\")\n",
    "    for item in data_dup:\n",
    "        show_img_by_path(item)\n",
    "    print(\"CLOSE IN COMPARE:\")\n",
    "    for item in compare_close:\n",
    "        show_img_by_path(item)\n",
    "    print(\"CLOSE IN DATA:\")\n",
    "    for item in data_close:\n",
    "        show_img_by_path(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if move_to(compare_dup, problems):\n",
    "    del(compare_dup)\n",
    "if move_to(data_dup, problems):\n",
    "    del(data_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Pickle behaviour for feature points.\n",
    "def _pickle_keypoints(point):\n",
    "    return cv2.KeyPoint, (*point.pt, point.size, point.angle,\n",
    "                          point.response, point.octave, point.class_id)\n",
    "\n",
    "# Register pickle handler for KeyPoints\n",
    "copyreg.pickle(cv2.KeyPoint().__class__, _pickle_keypoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_thread(item):\n",
    "    image = item[\"image\"]\n",
    "    points = image.split(\".\")[-2]+\".pts\"\n",
    "    detector = item[\"detector\"]\n",
    "\n",
    "    if not os.path.isfile(points):\n",
    "        try:\n",
    "            img = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "            kp, des = detector.detectAndCompute(img, None)\n",
    "            data = {\"kp\": kp, \"des\": des}\n",
    "            pickle.dump(data, open(points, \"wb\"))\n",
    "        except Exception as e:\n",
    "            print(\"{} failed because {}\".format(image, e))\n",
    "\n",
    "def feature_extraction(path, feature_detector=\"ORB\", points_num=8192):\n",
    "    # Get all images list.\n",
    "    files = glob.glob(path+\"*.jpg\")\n",
    "\n",
    "    detector = None\n",
    "    if feature_detector == \"SIFT\":\n",
    "        detector = cv2.SIFT_create(nfeatures=points_num)\n",
    "    elif feature_detector == \"SURF\":\n",
    "        detector = cv2.SURF_create(nfeatures=points_num)\n",
    "    elif feature_detector == \"ORB\":\n",
    "        # This is NOT scale-invariant, ughhh.\n",
    "        detector = cv2.ORB_create(nfeatures=points_num)\n",
    "    elif feature_detector == \"AKAZE\":\n",
    "        detector = cv2.AKAZE_create()\n",
    "\n",
    "    print(\"Detector used:\", detector)\n",
    "        \n",
    "    items = []\n",
    "    for image in files:\n",
    "        items.append({\"image\": image, \"detector\": detector})\n",
    "    \n",
    "    thread_it(extract_thread, items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "points_num = 2048\n",
    "features = \"AKAZE\"\n",
    "feature_extraction(compare_dir, feature_detector=features, points_num=points_num)\n",
    "feature_extraction(data_dir, feature_detector=features, points_num=points_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matcher(feature_detector=\"AKAZE\", bf_or_flann=\"BF\"):\n",
    "    #https://www.programcreek.com/python/?code=NetEase%2Fairtest%2Fairtest-master%2Fairtest%2Ftrash%2Ffind_obj.py\n",
    "    matcher, norm = None, None\n",
    "    if feature_detector in [\"ORB\", \"AKAZE\"]:\n",
    "        norm = cv2.NORM_HAMMING\n",
    "    elif feature_detector in [\"SIFT\", \"SURF\"]:\n",
    "        norm = cv2.NORM_L2\n",
    "    if bf_or_flann == \"FLANN\":\n",
    "        if norm == cv2.NORM_L2:\n",
    "            FLANN_INDEX_KDTREE = 1\n",
    "            flann_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "        else:\n",
    "            FLANN_INDEX_LSH = 6\n",
    "            flann_params= dict(algorithm = FLANN_INDEX_LSH,\n",
    "                                table_number = 6, # 12\n",
    "                                key_size = 12,     # 20\n",
    "                                multi_probe_level = 1) #2\n",
    "        matcher = cv2.FlannBasedMatcher(flann_params, {})\n",
    "        # bug : need to pass empty dict (#1329)\n",
    "    elif bf_or_flann == \"BF\":\n",
    "        matcher = cv2.BFMatcher(norm)\n",
    "    else:\n",
    "        matcher = cv2.BFMatcher(norm)\n",
    "\n",
    "    return matcher\n",
    "\n",
    "\n",
    "def match_within_path(path, matcher, ratio_test=False):\n",
    "    files = glob.glob(path+\"*.jpg\")\n",
    "    \n",
    "    tq = tqdm(total=len(files))\n",
    "    for img1 in files:\n",
    "        base1 = img1.split(\".\")[-2]\n",
    "        jpg1 = base1+\".jpg\"\n",
    "        features1 = pickle.load(open(base1+\".pts\", \"rb\"))\n",
    "        \n",
    "        if os.path.isfile(base1+\".mch\"):\n",
    "            matches1 = pickle.load(open(base1+\".mch\", \"rb\"))\n",
    "        else:\n",
    "            matches1 = {}\n",
    "            \n",
    "        for img2 in files:\n",
    "            # Skip if same image\n",
    "            if img1 is img2:\n",
    "                continue\n",
    "            \n",
    "            base2 = img2.split(\".\")[-2]\n",
    "            jpg2 = base2+\".jpg\"\n",
    "            features2 = pickle.load(open(base2+\".pts\", \"rb\"))\n",
    "            \n",
    "            # If either were matched against the other, fill out and skip\n",
    "            if os.path.isfile(base2+\".mch\"):\n",
    "                matches2 = pickle.load(open(base2+\".mch\", \"rb\"))\n",
    "                if jpg1 in matches2.keys():\n",
    "                    matches1[jpg2] = matches2[jpg1]\n",
    "                    continue\n",
    "                elif jpg2 in matches1.keys():\n",
    "                    matches2[jpg1] = matches1[jpg2]\n",
    "                    continue\n",
    "            else:\n",
    "                matches2 = {}\n",
    "\n",
    "            # Read computed data.\n",
    "            des1 = features1[\"des\"]  # Actual set image\n",
    "            des2 = features2[\"des\"]  # Compare set image\n",
    "            try:\n",
    "                matches_data = matcher.knnMatch(des1, des2, k=2)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                matches_data = []\n",
    "\n",
    "            if ratio_test:\n",
    "                # Apply ratio test\n",
    "                good = []\n",
    "                for m, n in matches_data:\n",
    "                    if m.distance < 0.75*n.distance:\n",
    "                        good.append(True)\n",
    "\n",
    "                matches1[jpg2] = len(good)\n",
    "                matches2[jpg1] = len(good)\n",
    "            else:\n",
    "                # Those that don't exist in here probably don't have matches can be removed\n",
    "                matches1[jpg2] = len(matches_data)\n",
    "                matches2[jpg1] = len(matches_data)\n",
    "\n",
    "            pickle.dump(matches2, open(base2+\".mch\", \"wb\"))\n",
    "        pickle.dump(matches1, open(base1+\".mch\", \"wb\"))\n",
    "        tq.update(1)\n",
    "\n",
    "\n",
    "def match_features_other_path(path, other_path, matcher, ratio_test=False):\n",
    "    # Get pre-computed images list.\n",
    "    files = glob.glob(path+\"*.pts\")\n",
    "    other = glob.glob(other_path+\"*.pts\")\n",
    "\n",
    "    tq = tqdm(total=len(files))\n",
    "    for img1 in files:\n",
    "        base1 = img1.split(\".\")[-2]\n",
    "        jpg1 = base1+\".jpg\"\n",
    "        \n",
    "        features1 = pickle.load(open(base1+\".pts\", \"rb\"))\n",
    "        if os.path.isfile(base1+\".mch\"):\n",
    "            matches = pickle.load(open(base1+\".mch\", \"rb\"))\n",
    "        else:\n",
    "            matches = {}\n",
    "            \n",
    "        for img2 in other:\n",
    "            # Skip if same image\n",
    "            if img1 is img2:\n",
    "                continue\n",
    "            \n",
    "            base2 = img2.split(\".\")[-2]\n",
    "            jpg2 = base2+\".jpg\"\n",
    "            \n",
    "            if jpg2 in matches.keys():\n",
    "                continue\n",
    "            \n",
    "            features2 = pickle.load(open(base2+\".pts\", \"rb\"))\n",
    "\n",
    "            # Read computed data.\n",
    "            des1 = features1[\"des\"]  # Actual set image\n",
    "            des2 = features2[\"des\"]  # Compare set image\n",
    "            try:\n",
    "                matches_data = matcher.knnMatch(des1, des2, k=2)\n",
    "            except Exception:\n",
    "                matches_data = []\n",
    "\n",
    "            if ratio_test:\n",
    "                # Apply ratio test\n",
    "                good = []\n",
    "                for m, n in matches_data:\n",
    "                    if m.distance < 0.75*n.distance:\n",
    "                        good.append(True)\n",
    "                        \n",
    "                matches[jpg2] = len(good)\n",
    "            else:\n",
    "                # Those that don't exist in here probably don't have matches can be removed\n",
    "                matches[jpg2] = len(matches_data)\n",
    "        tq.update(1)\n",
    "                \n",
    "\n",
    "        pickle.dump(matches, open(base1+\".mch\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "matcher = get_matcher(feature_detector=features, bf_or_flann=\"BF\") # Normally using BF, but, let's try FLANN\n",
    "print(matcher)\n",
    "\n",
    "match_within_path(compare_dir, matcher, ratio_test=True)\n",
    "match_features_other_path(data_dir, compare_dir, matcher, ratio_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "def load_and_total_matches(path):\n",
    "    files = glob.glob(path+\"*.jpg\")\n",
    "    matches = {}\n",
    "    for path in files:\n",
    "        match_path = path.split(\".\")[-2]+\".mch\"\n",
    "        matches[path] = pickle.load(open(match_path, \"rb\"))\n",
    "    return matches\n",
    "\n",
    "compare_matches = load_and_total_matches(compare_dir)\n",
    "data_matches = load_and_total_matches(data_dir)\n",
    "\n",
    "pprint(data_matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "print(\"COMPARISON SET:\")\n",
    "\n",
    "show_img_by_path('compare_set/image_0b74808c6f93d3eaa36d973a8aadb336.jpg')\n",
    "show_img_by_path('compare_set/image_0ef489424c1de58a34d126b3780deb5a.jpg')\n",
    "show_img_by_path('compare_set/image_4d319f3fcf359a10e879de21c93571ce.jpg')\n",
    "show_img_by_path('compare_set/image_6fb83397635551df36d4192de4129e9a.jpg')\n",
    "\n",
    "print(\"DATASET:\")\n",
    "for key, val in data_matches.items():\n",
    "    #show_img_by_path(key)\n",
    "    pprint(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def total_matches(matches, do_print=False):\n",
    "    totals = {}\n",
    "    for key in matches.keys():\n",
    "        totals[key] = []\n",
    "    for key, value in matches.items():\n",
    "        length = len(value)\n",
    "        for _, num_matches in value.items():\n",
    "            totals[key].append(num_matches)\n",
    "    for key in totals.keys():\n",
    "        totals[key] = sum(totals[key])\n",
    "\n",
    "    if do_print:\n",
    "        pprint(totals)\n",
    "    return totals\n",
    "\n",
    "compare_total_matches = total_matches(compare_matches)\n",
    "data_total_matches = total_matches(data_matches)\n",
    "\n",
    "pprint(compare_total_matches)\n",
    "pprint(data_total_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate threshold from comparison set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thr_from_compare(path, totals, multipler=1):\n",
    "    thr_per_image = {}\n",
    "    \n",
    "    tq = tqdm(total=len(totals))\n",
    "    for img1, item in totals.items():\n",
    "        for img2, val in item.items():\n",
    "            # Actual resolutions differences won't matter when using Scale-Invariant feature descriptions\n",
    "            # Only do multipler because references are the best case, real data won't be.\n",
    "            thr = val * multipler\n",
    "            \n",
    "            # Add thr to dict\n",
    "            if img2 not in thr_per_image.keys():\n",
    "                thr_per_image[img2] = [thr]\n",
    "            else:\n",
    "                thr_per_image[img2].append(thr)\n",
    "        tq.update(1)\n",
    "\n",
    "    # Get the average feature match for a valid image for each image in the reference set to every other image\n",
    "    for key in thr_per_image.keys():\n",
    "        val = thr_per_image[key]\n",
    "        thr_per_image[key] = sum(val)/len(val)\n",
    "        \n",
    "    return thr_per_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Does Lowe ratio apply here?\n",
    "#thr = thr*0.75\n",
    "\n",
    "thr_per_image = get_thr_from_compare(compare_dir, compare_matches, multipler=0.85)\n",
    "pprint(thr_per_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply threshold to data directory set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + exp(-x))\n",
    "\n",
    "\n",
    "def get_threshold_items(totals, thr_per_image, show=False):\n",
    "    values = {}\n",
    "    #x, y = [], []\n",
    "    tq = tqdm(total=len(totals))\n",
    "    for img1, item in totals.items():\n",
    "        # Get resolution\n",
    "        img = cv2.imread(img1, cv2.IMREAD_GRAYSCALE)\n",
    "        height, width = img.shape\n",
    "        res = width * height\n",
    "\n",
    "        rating = 0\n",
    "        \n",
    "        for img2, val in item.items():\n",
    "            # If the \"Data\" image is under the thr for the comparison image\n",
    "            if val > thr_per_image[img2]:\n",
    "                # Show which images from the comparison set, the data image is under thr for, and how much\n",
    "                rating += 1\n",
    "                \n",
    "        rating = rating / len(item) \n",
    "        #rating = sigmoid(rating)\n",
    "\n",
    "        values[img1] = rating\n",
    "        \n",
    "        tq.update(1)\n",
    "    \"\"\"    \n",
    "    if show:\n",
    "        %matplotlib notebook\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(200, 200))\n",
    "        plt.plot(y, x, \"o\", color=\"black\")\n",
    "        plt.plot([x for x in range(len(x))], [confidence for x in range(len(x))], '-ok', color=\"red\")\n",
    "        plt.xlabel(\"Number of features\")\n",
    "        plt.ylabel(\"Confidence\")\n",
    "        plt.show()\n",
    "        print(\"Average is \", confidence)\n",
    "    \"\"\"\n",
    "        \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ratings = get_threshold_items(data_matches, thr_per_image, show=False)\n",
    "#pprint(ratings)\n",
    "\n",
    "under_confidence = []\n",
    "confidence = sum(ratings.values()) / len(ratings)\n",
    "print(\"CONFIDENCE: {}\".format(confidence))\n",
    "for key, val in ratings.items():\n",
    "    if val < confidence:\n",
    "        print(key, \"@\", val)\n",
    "        under_confidence.append(key)\n",
    "        show_img_by_path(key, size=(75,75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_threshold_items(under, consider_folder, do_print=False):\n",
    "    for val in under:\n",
    "        if os.path.isfile(val):\n",
    "            filename = val.split(\"/\")[-1]\n",
    "            path = os.path.join(consider_folder, filename)\n",
    "            try:\n",
    "                shutil.move(val, consider_folder)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "        else:\n",
    "            print(val, \"doesn't exist\")\n",
    "\n",
    "move_threshold_items(under_confidence, consider_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}